<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Core-tuning论文阅读</title>
    <url>/4c2c1b49/</url>
    <content><![CDATA[<p>Core-tuning是一种finetune的方法，主要是提高自监督pretrained model在下游任务的性能。</p>
<p><strong>关键</strong></p>
<ul>
<li>正负样本</li>
<li>对比损失</li>
<li>权重</li>
</ul>
<a id="more"></a>
<h1 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h1><p>论文地址<a href="https://arxiv.org/abs/2102.06605">Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning</a></p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>使用<strong>contrastive loss</strong>，可以使模型在finetune过程中得到更好的优化和学习到更好的类区分表达能力</p>
<p>于是作者基于cross-entropy方法进行改进，将对比学习的思想融入到finetune方法中</p>
<h2 id="Cross-entropy的不足"><a href="#Cross-entropy的不足" class="headerlink" title="Cross-entropy的不足"></a>Cross-entropy的不足</h2><blockquote>
<p>Although cross-entropy tends to separate inter-class features, the resulting models still have limited capability for reducing intra-class feature scattering that exists in CSL models.  </p>
</blockquote>
<p>单纯使用cross-entropy，虽然可以分离不同类之间的特征，但在下游任务进行finetune时，不能很好地减少pretrained model已学习到的类之间区分特征的影响。</p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211021234925367.png" alt="image-20211021234925367"></p>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><p><strong>构建正负样本</strong></p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211021235714032.png" alt="image-20211021235714032"></p>
<p>作者采用features mixup策略来构建正负样本，不同于<a href="https://arxiv.org/pdf/2011.01403.pdf">论文</a><sup><a href="#fn_ 1" id="reffn_ 1"> 1</a></sup>单纯引入对比损失，更好地提高了finetune的效果</p>
<blockquote>
<p>Very recently, one work [19] explored contrastive learning to fine-tune language models. However, it simply add the contrastive loss to the objective of fine-tuning and cannot theoretically explain why it boosts fine-tuning.   </p>
</blockquote>
<ul>
<li>生成hard smaple pairs（正负样本对）来提高计算效能</li>
<li>同时平滑决策边界，提高了模型的泛化能力</li>
</ul>
<p><strong>contrast loss</strong></p>
<ul>
<li>在cross-entropy可以学习到不错的类之间区分能力的基础上，增加了额外的正则化。使得模型可以学到每个类的low-entropy feature cluster和high-entropy feature space，即同类聚集程度高，不同类间分离度大</li>
<li>优化contrastive loss可以比单纯使用cross-entropy收敛到更小的值，增加了额外的优化性能</li>
</ul>
<p><strong>总结</strong> </p>
<ul>
<li><p>论文中，对比损失和正负样本的构建这两个是相辅相成的</p>
</li>
<li><p>正负样本的构建，这是core-tuning实现的重要依赖</p>
<ul>
<li><blockquote>
<p> contrastive learning highly relies on positive/negative sample pairs, but the majority of sample features are easy-to-contrast and may produce negligible contrastive loss gradients. </p>
</blockquote>
</li>
</ul>
</li>
<li><p>contrast loss也是通过正负样本才能对让模型对类更好地区分，同时平滑决策边界</p>
</li>
</ul>
<h1 id="方法与实现"><a href="#方法与实现" class="headerlink" title="方法与实现"></a>方法与实现</h1><h2 id="对比损失函数"><a href="#对比损失函数" class="headerlink" title="对比损失函数"></a>对比损失函数</h2><p>给定一个样本特征$z_i$作为anchor，$A_i$为anchor $z_i$集合，将与anchor同类的作为positive pairs，集合记为$P_i$，不同类的作为negative pairs，所有特征经过$l_2-normalized$</p>
<script type="math/tex; mode=display">
L_{con}=-\frac{1}{n|P_i|}\sum^{n}_{i=1}\sum_{z_j\in P_i}log\frac{e^{(z^T_iz_j/\tau)}}{\sum_{z_k\in A_i}e^{z^T_iz_k/\tau}}</script><p><strong>理论证明推导后续补充……</strong></p>
<h2 id="构建正负样本"><a href="#构建正负样本" class="headerlink" title="构建正负样本"></a>构建正负样本</h2><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022000428639.png" alt="image-20211022000428639"></p>
<p><strong>Mixing hard positive pairs</strong></p>
<p>通过计算余弦相似度来选择hardest positive data和hardest negative data</p>
<p>$z^{hp}$在正样本里与anchor相似度最低，$z^{hn}$在负样本里与anchor相似度最高</p>
<p><strong>Mixing hard negative pairs</strong></p>
<p>随机选择一个负样本</p>
<p><strong>总结</strong></p>
<p>一个batch中的每一个样本（称为anchor）均对应生成一个正样本和一个负样本，故<strong>总样本规模为3xbatch_size</strong></p>
<ul>
<li><p>正样本包含两部分：positive data 和 negative data， 通过$\lambda$控制权重</p>
<ul>
<li>positive： 选取该batch样本中与anchor同类，但特征相似度最小的样本</li>
<li>negative：选取该batch样本中与anchor不同类，但特征相似度最高的样本</li>
<li>该样本是由positive 和 negative 合成得到的，可能是不存在于原batch样本中的</li>
</ul>
</li>
<li><p>负样本为batch中随机抽取与anchor不同类的样本，但开源代码实现中，可能为与anchor同类的样本，但作者说不会对性能造成影响</p>
<ul>
<li><div class="hljs code-wrapper"><pre><code class="lang-python"># hard negative pair generation. 
    order = np.arange(batch_size) 
    random.shuffle(order)   
    # We randomly shuffle the sample order to find negative pairs. Even if a few pairs are not negative here, it won&#39;t affect the overall functionality. 
    features2 = features[order]    
    y_2 = one_hot_labels[order]
</code></pre></div>
</li>
<li><p>该样本是由positive 和 negative 合成得到的，可能是不存在于原batch样本中的</p>
</li>
</ul>
</li>
</ul>
<h2 id="权重设置"><a href="#权重设置" class="headerlink" title="权重设置"></a>权重设置</h2><p><strong>Hard Positive Reweighting</strong></p>
<p>作者认为，hard positives 在对比学习中包含更多有用的信息，因此提高相应的权重</p>
<blockquote>
<p>However, since hard pairs are more informative for contrastive learning, we propose to assign higher importance weights to hard positive pairs.  </p>
</blockquote>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022000536552.png" alt="image-20211022000536552"></p>
<p><strong>Smooth Classifier Learning</strong></p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022000624169.png" alt="image-20211022000624169"></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022001442803.png" alt="image-20211022001442803"></p>
<p>由于目前还没有其它应用于自监督pretrained model finetune的loss计算方法，作者将cross-entropy在supervised上的finetune作为baseline，其它在supervised上finetune的方法应用于训练自监督pretrained model作为参考</p>
<p>实验证明，Core-tuning对自监督pretrianed model的训练效果不错。</p>
<p>（有时间阅读表格中的finetune方法）</p>
<h2 id="值得注意的图表"><a href="#值得注意的图表" class="headerlink" title="值得注意的图表"></a>值得注意的图表</h2><p><strong>平滑边界</strong></p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022001656128.png" alt="image-20211022001656128"></p>
<p>可以看出平滑边界是一个有效提高性能的方法，<strong>需掌握</strong></p>
<p><strong>思考</strong></p>
<ul>
<li>是否有其他实现平滑边界的方法？</li>
</ul>
<p><strong>正负样本</strong></p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022002150119.png" alt="image-20211022002150119"></p>
<p>可以看出，正负样本对于contrast loss的性能是有一定影响的，<strong>需掌握</strong></p>
<p><strong>思考</strong></p>
<ul>
<li>正负样本的构建方法是否可替代？</li>
</ul>
<p><strong>权重设置</strong></p>
<p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211022002657690.png" alt="image-20211022002657690"></p>
<p>作者觉得contrast loss更应该关注正样本的信息，于是提高相应权重</p>
<blockquote>
<p>That is, contrastive learning highly relies on positive/negative sample pairs, but the majority of sample features are easy-to-contrast (cf. Figure 1 (a)) [20, 60] and may produce negligible contrastive loss gradients.  </p>
</blockquote>
<p><strong>思考</strong></p>
<ul>
<li>正样本的作用，为什么是关键</li>
<li>实现权重分配的方法</li>
<li>权重分配思想，<strong>需牢记</strong></li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>个人感觉，core-tuning是来优化自监督网络的pretrained model，本身的训练过程和自监督是没有关系的，实际做的是有监督训练。</p>
<p>但作者把对比学习的思想融入进来是一个不错的idea，而且构建正负样本也很有意思，值得学习和借鉴。</p>
<p><strong>思考</strong></p>
<ul>
<li><p>正样本为两个不同类样本的合成，因此会是一个新的“类”，原本两个样本处于这两个类的分离边界附近</p>
<ul>
<li><p>由此加入正样本训练可以使得，正样本与原两个样本远离（因为是不同类），促使原两个样本类在训练过程中分离更快？</p>
</li>
<li><blockquote>
<p>the majority of sample pairs are easy-to-contrast, which may induce negligible contrastive loss gradients that contribute little to<br>learning discriminative representations.  </p>
</blockquote>
</li>
<li><p>是否可以调整挑选样本指标，如正样本由三个相邻的不同类的样本合成，是否也可能促进三个类分离更快？</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>由于负样本与anchor相似度较小(默认$\lambda &gt;= 0.8$)，与不同类相似度较高，由此处于类的边界地带</p>
<ul>
<li>加入正负样本可以使得训练过程中，缓和不同类之间的差异，使得决策边界更平滑。</li>
</ul>
</li>
</ul>
<blockquote id="fn_ 1">
<sup> 1</sup>. Beliz Gunel, Jingfei Du, Alexis Conneau, and Ves Stoyanov. Supervised contrastive learning for pre-trained language model fine-tuning. In International Conference on Learning Representations, 2021.<a href="#reffn_ 1" title="Jump back to footnote [ 1] in the text."> &#8617;</a>
</blockquote>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>迁移学习</tag>
        <tag>自监督</tag>
      </tags>
  </entry>
  <entry>
    <title>MNE论文阅读</title>
    <url>/8af5cf34/</url>
    <content><![CDATA[<p>MNE通过融合相邻特征进行特征增强操作，在image search 和 few shot learning task(小样本学习)上取得不错的效果</p>
<p><strong>关键</strong></p>
<ul>
<li>融合样本特征的<strong>相邻样本</strong></li>
<li>记忆存储模块 episodic memory</li>
<li>树结构</li>
</ul>
<a id="more"></a>
<h1 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h1><p>论文地址<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Memory-Based_Neighbourhood_Embedding_for_Visual_Recognition_ICCV_2019_paper.pdf">Memory-Based Neighbourhood Embedding for Visual Recognition</a></p>
<p>MNE通过融合相邻特征进行特征增强操作，在视觉识别上取得不错的效果</p>
<p><strong>关键</strong></p>
<ul>
<li>融合样本特征的<strong>相邻样本</strong></li>
<li>记忆存储模块 episodic memory<ul>
<li>存放<strong>多个batch</strong>的特征，在该模块中寻找样本特征的相邻特征</li>
</ul>
</li>
<li><p>树结构，<strong>自下而上</strong>融合特征</p>
<ul>
<li>样本特征位于根节点，采用<strong>k-mean方法</strong>查找相邻特征，放置于叶子结点</li>
<li><strong>迭代式</strong>自下而上融合相邻特征</li>
<li>结合<strong>attention机制</strong>，采用<strong>有监督</strong>的方式，提高同类别或相似类别的相邻特征的融合权重 </li>
</ul>
</li>
<li><p><strong>多loss训练</strong></p>
</li>
</ul>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/Pasted image 20211104183941.png" alt="Pasted image 20211104183941"></p>
<p><strong>相同类别或相似类别的图像在映射到语义空间中也是相似或相邻的</strong></p>
<blockquote>
<p>   Images from the same or related classes are desired to  be mapped to nearby points on a manifold, which is critical to many applications like few-shot learning [41, 31, 37],   visual search [7, 13, 45], face/person recognition [20, 26,  43, 2] and fine-grained retrieval [19, 18].</p>
</blockquote>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul>
<li>结合<strong>Context-based Feature Learning</strong><ul>
<li>采用k-mean方式寻找相邻特征，并融合到样本特征中</li>
</ul>
</li>
<li>结合<strong>GNN</strong><ul>
<li>采用树结构来构造样本特征和相邻特征的关系</li>
<li>结合attention机制，自下而上融合相邻特征信息到样本特征中</li>
</ul>
</li>
</ul>
<h1 id="方法与实现"><a href="#方法与实现" class="headerlink" title="方法与实现"></a>方法与实现</h1><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul>
<li>作者采用k-mean查找相邻特征<ul>
<li>通过计算特征间余弦相似度是否可以</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>特征增强</tag>
        <tag>多loss</tag>
      </tags>
  </entry>
  <entry>
    <title>RepMLP论文阅读</title>
    <url>/bbac9d9a/</url>
    <content><![CDATA[<p>RepMLP利用<strong>结构重参数化</strong>对MLP进行改进，优化了传统MLP模型参数规模大，训练速度慢等缺点。</p>
<p><strong>关键</strong></p>
<ul>
<li>结构重参数化<ul>
<li>卷积和FC的转换，分组FC</li>
</ul>
</li>
<li>图片的三要素<ul>
<li>local prior，global capacity， positional perception</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h1 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h1><p>论文地址<a href="https://arxiv.org/pdf/2105.01883.pdf">RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition</a></p>
<p>详细讲解可看作者在知乎的论文解读<a href="https://zhuanlan.zhihu.com/p/375422742">热点讨论：MLP，RepMLP，全连接与“内卷”</a></p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/image-20211023004702079.png" alt="image-20211023004702079"></p>
<p>利用<strong>结构重参数化</strong>提高MLP性能，采用training和inference的训练模式。</p>
<ul>
<li><p>整体结构</p>
<ul>
<li>training: Global Perceptron, Partition Perceptron, Local Perceptron</li>
<li>inference: 将training的三个结构转换为单纯的FC</li>
</ul>
</li>
<li><p>为什么选择MLP</p>
<ul>
<li>FC可以很好地捕获全局信息，但不能捕获局部信息<blockquote>
<p>Compared to convolutional layers, FC layers are more efficient,<br>better at modeling the long-range dependencies and positional patterns, but worse at capturing the local structures, hence usually less favored for image recognition.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>利用卷积结构</p>
<ul>
<li>卷积可以很好地学习到局部信息</li>
</ul>
</li>
<li><p>应用场景</p>
<ul>
<li>RepMLP主要是为提高准确率和吞吐量而设计的，而不是为了更少的参数<blockquote>
<p>   It should not be left unmentioned that RepMLP is designed for the application scenarios where the major concerns are the inference throughput  and accuracy, less concerning the number of parameters.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="CNN的优点与不足"><a href="#CNN的优点与不足" class="headerlink" title="CNN的优点与不足"></a>CNN的优点与不足</h2><p><strong>优点</strong></p>
<ul>
<li>卷积可以很好的捕获一张图片的局部信息<ul>
<li><strong>local prior</strong>: 图片中某一个像素点与其周围像素点的关联程度要比更远距离的像素点的关联程度的大</li>
<li>通过卷积核可以将一个像素点和其周围像素点的特征联系起来，这也是CNN成功的原因之一<blockquote>
<p>   The locality of images (i.e., a pixel is more related to its neighbors than the distant pixels) makes Convolutional Neural Network (ConvNet) successful in image recognition, as a conv layer only processes a local neighborhood.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>传统CNN通过堆叠卷积层来捕获全局信息，但效果差，成本高</li>
</ul>
<blockquote>
<p>   Traditional ConvNets model  the long-range dependencies by the large receptive fields formed by deep stacks of conv layers [29]. However, repeating local operations is computationally inefficient and may cause optimization difficulties.</p>
</blockquote>
<h2 id="FC的优势及改进方法"><a href="#FC的优势及改进方法" class="headerlink" title="FC的优势及改进方法"></a>FC的优势及改进方法</h2><p><strong>优势</strong></p>
<ul>
<li>对比于CNN，FC可以捕获到图片的全局信息和位置信息</li>
</ul>
<blockquote>
<p>   we can enjoy the positional perception (because its parameters are position-related) and global capacity (because every output point is related to every input  point).</p>
</blockquote>
<p><strong>结构重参数化</strong></p>
<ul>
<li><p>Global Perceptron</p>
<ul>
<li>对feature map进行<strong>切分</strong>，可以减少参数量，但是破坏了不同块之间的联系</li>
<li><blockquote>
<p>   However, splitting breaks the correlations among different partitions of the same channel. In other words, the model will view the partitions separately, totally unaware that they were positioned side by side</p>
</blockquote>
</li>
<li>通过<strong>平均池化层</strong>来学习不同块之间的联系，然后通过<strong>BN+2 layersMLP</strong>(需思考为什么)，由于<strong>自动广播</strong>机制可以直接相加</li>
</ul>
</li>
<li><p>Partition Perceptron</p>
<ul>
<li>参考分组卷积使用分组FC，可以减少参数量</li>
<li>实现：将一维vector转化为二维feature map，采用1x1的卷积核实现分组卷积，再转换为一维vector，实现分组FC(值得学习的思路)</li>
</ul>
</li>
<li><p>Local Perceptron</p>
<ul>
<li>保持分辨率不变，经过多个卷积分支，分组数量与Partition Perceptron相同。(需思考为什么)</li>
</ul>
</li>
</ul>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul>
<li>利用了图像的三个要素，全局信息，局部信息，位置信息</li>
<li><p>结构重参数化</p>
<ul>
<li>提出一种简单的转换方式</li>
</ul>
</li>
<li><p>采用FC分组</p>
</li>
</ul>
<h1 id="方法与实现"><a href="#方法与实现" class="headerlink" title="方法与实现"></a>方法与实现</h1><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>RepMLP是MLP的变体，解决的传统MLP开销大的问题，同时也可以替换CNN模型中的MLP层，从而提高模型性能。</p>
<p><strong>思考</strong></p>
<ul>
<li>理解卷积是一种特殊的FC，存在一个FC可以替代卷积核操作（阅读代码，加深理解）</li>
<li><p>借鉴分组卷积使用分组FC，作者采用升维方式，利用1x1卷积核实现分组</p>
<ul>
<li>分组思想是否有别的应用（思考）</li>
<li>升维思想，维度转换的灵活应用，特殊卷积核的使用</li>
</ul>
</li>
<li><p>图片的三要素包含了图像的丰富信息</p>
</li>
<li>参数转换策略</li>
</ul>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>结构重参数化</tag>
      </tags>
  </entry>
  <entry>
    <title>已读论文</title>
    <url>/39c6cef1/</url>
    <content><![CDATA[<p>目前已读的论文列表</p>
<a id="more"></a>
<ul>
<li>Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning <ul>
<li><a href="https://arxiv.org/pdf/2102.06605.pdf">PDF</a> <a href="https://mihaoyoung.github.io/4c2c1b49/">论文阅读</a></li>
<li>迁移学习，自监督，特征增强</li>
</ul>
</li>
<li>RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition<ul>
<li><a href="https://arxiv.org/pdf/2105.01883.pdf">PDF</a> <a href="https://mihaoyoung.github.io/bbac9d9a/">论文阅读</a></li>
<li>MLP，结构重参数化</li>
</ul>
</li>
<li>Improve Unsupervised Pretraining for Few-label Transfer <ul>
<li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Improve_Unsupervised_Pretraining_for_Few-Label_Transfer_ICCV_2021_paper.pdf">PDF</a> <a href="https://mihaoyoung.github.io/3847555c/">论文阅读</a></li>
<li>特征增强，多loss，小样本学习</li>
</ul>
</li>
<li>Memory-Based Neighbourhood Embedding for Visual Recognition <ul>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Memory-Based_Neighbourhood_Embedding_for_Visual_Recognition_ICCV_2019_paper.pdf">PDF</a> <a href="https://mihaoyoung.github.io/8af5cf34/">论文阅读</a></li>
<li>迁移学习，无监督，小样本学习</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>TUP论文阅读</title>
    <url>/3847555c/</url>
    <content><![CDATA[<p>TUP将target dataset加入到source dataset中，一起进行自监督预训练（如MOCO），之后对pretrained model在target dataset上采用ACKMeans进行finetune</p>
<p><strong>关键</strong></p>
<ul>
<li>dataset合并</li>
<li>ACKMeans</li>
</ul>
<a id="more"></a>
<h1 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h1><p>论文地址<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Improve_Unsupervised_Pretraining_for_Few-Label_Transfer_ICCV_2021_paper.pdf">Improve Unsupervised Pretraining for Few-label Transfer</a></p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/Pasted image 20211104213800.png" alt="Pasted image 20211104213800"></p>
<p>将无标注的target dataset（实际上每类至少有一个标注）和无标注的source dataset一起进行自监督预训练，称为<strong>Target-aware Unsupervised Pretraining</strong>，因此pretrained model的features representation对target dataset有很好的聚类作用，TUP借助聚类可以找到<strong>eigen-samples</strong>，即聚类中心的样本，通过该样本对其他无标注样本进行标注，从而利用这些伪标注样本进行finetune，可以得到一个好的特征表达。而好的特征表达还可以为下一轮的训练找到更好的eigen-samples，从而起到一个环的效果。</p>
<h2 id="聚类信息的优点"><a href="#聚类信息的优点" class="headerlink" title="聚类信息的优点"></a>聚类信息的优点</h2><p><img src="https://gitee.com/mihaoyoung/blog_image/raw/master/Pasted image 20211104215852.png" alt="Pasted image 20211104215852"></p>
<p>作者对比了无标注目标数据集在无监督pretrained model和有监督pretrained model的聚类效果，发现有监督的聚类效果更好，从而finetune的结果也更好。</p>
<p>因此作者认为，如果无标注目标数据集在无监督上也可以取得不错的聚类效果，那么就可以提高finetune的性能。</p>
<h2 id="自监督的聚类效果不好的原因"><a href="#自监督的聚类效果不好的原因" class="headerlink" title="自监督的聚类效果不好的原因"></a>自监督的聚类效果不好的原因</h2><p>自监督网络采用对比学习的方式，将同类的样本聚集，不同类的样本远离。</p>
<p>假设特征空间是一个球体，那么对比学习使得特征信息分布在了整个球体上。</p>
<blockquote>
<p>   In this sense, we can find that contrastive learning is indeed to cluster the pretraining unlabeled data, but it encourages the learned representation to  uniformly distribute in the whole space.</p>
</blockquote>
<p>因此，当目标数据集的分布和源数据集的分布相差很大时，目标数据集就无法在无监督预训练模型上得到一个好的聚类效果。</p>
<blockquote>
<p>   Therefore, if the  target dataset has some domain gap with the source dataset,  their feature representations will scatter and hard to cluster.</p>
</blockquote>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul>
<li>dataset合并<ul>
<li>通过合并目标数据集和源数据集，自监督预训练model可以学到一个更适合目标数据集的特征表示，从而目标数据集在该模型的特征表示中有<strong>更好的聚类效果</strong></li>
<li>对于两个数据集的<strong>权重占比</strong>，是一个值得考虑的问题</li>
</ul>
</li>
<li>ACKMeans<ul>
<li>将锚点引入到传统的KMeans算法中，提高了聚类的多样化和全面性</li>
</ul>
</li>
</ul>
<h1 id="方法与实现"><a href="#方法与实现" class="headerlink" title="方法与实现"></a>方法与实现</h1><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>TUP是finetune在无监督上的有效尝试，并且也取得不错的效果。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul>
<li>TUP始终还是利用了少许的标签信息，是否可以再一步优化，进行完全无监督finetune</li>
<li>预训练成本高，是否有其他将target dataset信息融入到预训练模型的方法<ul>
<li>source pretrained + target pretrained + finetune 可不可行？</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>迁移学习</tag>
        <tag>无监督</tag>
      </tags>
  </entry>
</search>
